{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 2: Maximal/Closed frequent itemsets (lenguaje de programación R o Python)\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "Utilice el dataset que se desee, puede ser uno creado por vosotros o cualquiera que descarguéis por internet. Tiene que ser en formato CSV. CONSEJO: utilizad un dataset pequeño en cuanto a numero de ítems y registros/transacciones.\n",
    "\n",
    "- Implemente un algoritmo que permita descubrir los `maximal itemsets` que existen en ese dataset.\n",
    "\n",
    "- Implemente un algoritmo que permita descubrir los `closed itemsets` que existen en ese dataset.\n",
    "\n",
    "- Entregue el código y el dataset, así como un fichero (txt, pdf) que explique cómo ejecutar el código. Debe incluir también una explicación a la metodología utilizada (explicación del algoritmo realizado).\n",
    "\n",
    "- Importante: Se debe entregar un código con una implementación propia, sin invocar a librerías externas. Se permite el uso de una implementación externa para obtener previamente los frequent itemsets, pero en ese caso no se otorgará la máxima calificación.\n",
    "\n",
    "Evaluación: se analizará la limpieza y claridad del código. Se evaluará la eficiencia de los algoritmos cuando se ejecuten sobre un dataset modelo que se usará para todos los alumnos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que se va a utilizar es `Car Acceptability Classification Dataset`, disponible en https://www.kaggle.com/datasets/subhajeetdas/car-acceptability-classification-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Es máximo si no tiene ningún superconjunto frecuente. Es cerrado si ninguno de sus superconjuntos inmediatos tiene  el mismo soporte que ese itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\":\".join(\"test\".split(\":\")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, items, ocurrences, isPad = False):\n",
    "        self.items = items.split(\":\")\n",
    "        self.ocurrences = ocurrences\n",
    "        self.children = []\n",
    "        self.best_children = []\n",
    "        self.parents = []\n",
    "        self.locked = True\n",
    "        self.isPad = isPad\n",
    "\n",
    "    def add_if_child(self, child):\n",
    "        if self.isPad:\n",
    "            self.children.append(child)\n",
    "            return\n",
    "        \n",
    "        for item in child.items:\n",
    "            if item not in self.items:\n",
    "                return\n",
    "        self.children.append(child)\n",
    "\n",
    "    def add_parent(self, parent):\n",
    "        if parent.isPad:\n",
    "            self.parents.append(parent)\n",
    "            return\n",
    "        for item in self.items:\n",
    "            if item not in parent.items:\n",
    "                return\n",
    "        self.parents.append(parent)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.items) + \" : support(\" + str(self.ocurrences) + \")\"\n",
    "\n",
    "    def select_parent(self, selected_parent):\n",
    "        #En vez de eliminar arcos, se crea un arco fuerte\n",
    "        self.best_parent = selected_parent\n",
    "        selected_parent.add_best_child(self)\n",
    "\n",
    "    def add_best_child(self, child):\n",
    "        self.best_children.append(child)\n",
    "\n",
    "\n",
    "\n",
    "class FPGrowth:\n",
    "    FILE = \"car.csv\"\n",
    "    SEPARATOR = \",\"\n",
    "\n",
    "    def __init__(self, file = FILE, separator = SEPARATOR):\n",
    "        self.file = file\n",
    "        self.separator = separator\n",
    "        self.__load_data__()\n",
    "\n",
    "\n",
    "    def __combinations__(self, items):\n",
    "        if not items:\n",
    "            return []\n",
    "\n",
    "        first = items[0]\n",
    "        rest = items[1:]\n",
    "\n",
    "        combs_without_first = self.__combinations__(rest)\n",
    "\n",
    "        combs_with_first = []\n",
    "        for comb_str in combs_without_first:\n",
    "            combs_with_first.append(first + \":\" + comb_str)\n",
    "        combs_with_first.append(str(first))\n",
    "\n",
    "        return combs_with_first + combs_without_first\n",
    "\n",
    "    def __load_data__(self):\n",
    "        \n",
    "        \n",
    "        self.entries = 0\n",
    "        self.raw_ocurrences_per_len = {} #itemset : ocurrences El itemset tiene el formato \"1_a:2_b:3_c\"\n",
    "\n",
    "        print(\"Counting ocurrences\")\n",
    "        with open(self.file, \"r\") as file:\n",
    "            self.header = file.readline().strip().split(self.separator)\n",
    "\n",
    "            for line in file:\n",
    "                self.entries += 1\n",
    "                items = line.strip().split(self.separator)\n",
    "                real_items = []\n",
    "                for index, item in enumerate(items):\n",
    "                    if len(item) > 0:\n",
    "                        real_items.append(self.header[index] + \"_\" + item)\n",
    "                \n",
    "                if len(real_items) == 0:\n",
    "                    continue\n",
    "                itemsets = self.__combinations__(real_items)\n",
    "\n",
    "                for itemset in itemsets:\n",
    "                    itemset_length = len(itemset.split(\":\"))\n",
    "                    if itemset_length not in self.raw_ocurrences_per_len:\n",
    "                        self.raw_ocurrences_per_len[itemset_length] = {}\n",
    "                    if itemset not in self.raw_ocurrences_per_len[itemset_length]:\n",
    "                        self.raw_ocurrences_per_len[itemset_length][itemset] = 0\n",
    "                    self.raw_ocurrences_per_len[itemset_length][itemset] += 1\n",
    "\n",
    "        print(\"Building tree\")\n",
    "        self.ocurrences = []\n",
    "        ordered_lengths = sorted(self.raw_ocurrences_per_len.keys(), reverse=True)\n",
    "        \n",
    "        for cur_ocurrences, cur_value in self.raw_ocurrences_per_len[ordered_lengths[0]].items():\n",
    "            self.ocurrences.append(Node(cur_ocurrences, cur_value))\n",
    "\n",
    "        pad_parent = Node(\":\" * (ordered_lengths[0] -1), -1, True)\n",
    "        self.ocurrences.append(pad_parent)\n",
    "\n",
    "        last_ocurrences = self.ocurrences\n",
    "        ocurrences_per_level = {} #No contiene los nodos de mayor nivel. Se usará para eliminar arcos redundantes.\n",
    "        for current_length in ordered_lengths[1:]:\n",
    "            new_ocurrences = []\n",
    "            ocurrences_per_level[current_length] = []\n",
    "            no_match = []\n",
    "            for cur_ocurrences, cur_value in self.raw_ocurrences_per_len[current_length].items():\n",
    "                ocurrence = Node(cur_ocurrences, cur_value)\n",
    "                matches = 0\n",
    "                \n",
    "                for last_ocurrence in last_ocurrences:\n",
    "                    last_ocurrence.add_if_child(ocurrence)\n",
    "                    ocurrence.add_parent(last_ocurrence)\n",
    "                    matches += 1\n",
    "                if matches == 0:\n",
    "                    no_match.append(ocurrence)\n",
    "\n",
    "                ocurrences_per_level[current_length].append(ocurrence)\n",
    "                new_ocurrences.append(ocurrence)\n",
    "\n",
    "            if len(no_match) > 0:\n",
    "                current_level_pad = Node(\":\" * (current_length -1), -1, True)\n",
    "                for no_match_item in no_match:\n",
    "                    no_match_item.add_parent(current_level_pad)\n",
    "                    current_level_pad.add_child(no_match_item)\n",
    "                new_ocurrences.append(current_level_pad)\n",
    "                ocurrences_per_level[current_length].append(current_level_pad)\n",
    "            \n",
    "            last_ocurrences = new_ocurrences\n",
    "\n",
    "        print(\"Selecting best parents\")\n",
    "        ordered_lengths = sorted(ocurrences_per_level.keys())\n",
    "\n",
    "        for current_length in ordered_lengths:\n",
    "            for keyset in ocurrences_per_level[current_length]:\n",
    "                self.select_best_parent(keyset)\n",
    "\n",
    "\n",
    "    def select_best_parent(self, node):\n",
    "        parents = {}\n",
    "        for parent in node.parents:\n",
    "            parent_ocurrences = parent.ocurrences\n",
    "            if parent_ocurrences not in parents:\n",
    "                parents[parent_ocurrences] = []\n",
    "            parents[parent_ocurrences].append(parent)\n",
    "        \n",
    "        max_ocurrences = max(parents.keys())\n",
    "        selected_parent = parents[max_ocurrences][0]\n",
    "        node.select_parent(selected_parent)\n",
    "    \n",
    "\n",
    "    def __get_max_itemsets__(self, node, support):\n",
    "        if node.ocurrences >= support:\n",
    "            return [str(node)]\n",
    "        \n",
    "        max_itemsets = []\n",
    "        for child in node.best_children:\n",
    "            max_itemsets.append(self.__get_max_itemsets__(child, support))\n",
    "\n",
    "        return max_itemsets\n",
    "    \n",
    "    def __get_closed_itemsets__(self, node, support):\n",
    "        closed_itemsets = []\n",
    "        #check if node is closed\n",
    "        if node.ocurrences >= support:\n",
    "            closed = True\n",
    "            for parent in node.parents:\n",
    "                if parent.ocurrences == node.ocurrences:\n",
    "                    closed = False\n",
    "                    break\n",
    "            if closed:\n",
    "                closed_itemsets.append(str(node))\n",
    "        \n",
    "        for child in node.best_children:\n",
    "            for child_closed_itemset in self.__get_closed_itemsets__(child, support):\n",
    "                if len(child_closed_itemset) > 0:\n",
    "                    closed_itemsets.append(child_closed_itemset)\n",
    "\n",
    "        return closed_itemsets\n",
    "        \n",
    "\n",
    "\n",
    "    def maximal_itemsets(self, minimum_support):\n",
    "        minimum_occurrences = self.entries * minimum_support\n",
    "\n",
    "        maximal_itemsets = []\n",
    "        for itemset in self.ocurrences:\n",
    "            for max_itemset in self.__get_max_itemsets__(itemset, minimum_occurrences):\n",
    "                if len(max_itemset) > 0:\n",
    "                    maximal_itemsets.append(max_itemset)\n",
    "        return maximal_itemsets\n",
    "    \n",
    "\n",
    "    def closed_itemsets(self, minimum_support):\n",
    "        minimum_occurrences = self.entries * minimum_support\n",
    "\n",
    "        closed_itemsets = []\n",
    "        for itemset in self.ocurrences:\n",
    "            for closed_itemset in self.__get_closed_itemsets__(itemset, minimum_occurrences):\n",
    "                if len(closed_itemset) > 0:\n",
    "                    closed_itemsets.append(closed_itemset)\n",
    "\n",
    "        return closed_itemsets\n",
    "            \n",
    "\n",
    "            \n",
    "                \n",
    "    \n",
    "    #Es cerrado si ninguno de sus superconjuntos inmediatos tiene  el mismo soporte que ese itemset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting ocurrences\n",
      "Building tree\n",
      "Selecting best parents\n",
      "[[\"['A_a', 'B_b'] : 3\"], [[\"['C_c'] : 3\"]], [[\"['D_d'] : 3\"]]]\n",
      "-----\n",
      "[\"['A_a', 'B_b', 'C_c'] : 1\", \"['A_a', 'B_b'] : 3\", \"['A_a'] : 4\", \"['B_b'] : 4\", \"['B_b', 'C_c'] : 2\", \"['C_c'] : 3\", \"['A_a', 'B_b', 'D_d'] : 1\", \"['A_a', 'D_d'] : 2\", \"['D_d'] : 3\", \"['C_c', 'D_d'] : 1\"]\n"
     ]
    }
   ],
   "source": [
    "testFPG = FPGrowth(file = \"test.csv\")\n",
    "\n",
    "print(testFPG.maximal_itemsets(minimum_support=0.5))\n",
    "print(\"-----\")\n",
    "print(testFPG.closed_itemsets(minimum_support=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting ocurrences\n",
      "Building tree\n",
      "Selecting best parents\n",
      "1728\n",
      "12638\n"
     ]
    }
   ],
   "source": [
    "fpg = FPGrowth(file = \"car.csv\")\n",
    "print(len(fpg.maximal_itemsets(0.0)))\n",
    "print(len(fpg.closed_itemsets(0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal (1728) < Closed (2356)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximal ({len(maximal)}) < Closed ({len(closed)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
